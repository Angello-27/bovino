#!/usr/bin/env python3
"""
üîç Verificaci√≥n Completa del Modelo Bovino
"""

import os
import json
import logging
import numpy as np
import tensorflow as tf
from pathlib import Path
import time

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def verify_model_files():
    """Verificar que existen los archivos del modelo"""
    print("üîç VERIFICACI√ìN DE ARCHIVOS DEL MODELO")
    print("=" * 50)
    
    model_path = Path("models/bovino_model.h5")
    labels_path = Path("models/class_labels.json")
    
    # Verificar archivos
    files_status = {
        "Modelo (.h5)": model_path.exists(),
        "Etiquetas (.json)": labels_path.exists(),
    }
    
    all_exist = True
    for file_name, exists in files_status.items():
        status = "‚úÖ" if exists else "‚ùå"
        print(f"{status} {file_name}")
        if not exists:
            all_exist = False
    
    if not all_exist:
        print("\n‚ùå Faltan archivos del modelo")
        print("üí° Ejecuta: python train_model.py para entrenar el modelo")
        return False
    
    # Mostrar informaci√≥n de archivos
    print(f"\nüìä Informaci√≥n de archivos:")
    model_size = model_path.stat().st_size / (1024 * 1024)  # MB
    print(f"   Modelo: {model_size:.1f} MB")
    
    with open(labels_path, 'r', encoding='utf-8') as f:
        labels = json.load(f)
    print(f"   Etiquetas: {len(labels)} razas")
    
    return True

def test_model_loading():
    """Probar carga del modelo"""
    print("\nüì• PRUEBA DE CARGA DEL MODELO")
    print("=" * 50)
    
    try:
        model_path = Path("models/bovino_model.h5")
        
        # Medir tiempo de carga
        start_time = time.time()
        model = tf.keras.models.load_model(str(model_path))
        load_time = time.time() - start_time
        
        # Verificar que el modelo se carg√≥ correctamente
        if model is None:
            raise Exception("El modelo se carg√≥ como None")
        
        print(f"‚úÖ Modelo cargado exitosamente")
        print(f"‚è±Ô∏è Tiempo de carga: {load_time:.2f} segundos")
        print(f"üìä Par√°metros: {model.count_params():,}")
        print(f"üèóÔ∏è Arquitectura:")
        print(f"   Entrada: {model.input_shape}")
        print(f"   Salida: {model.output_shape}")
        print(f"   Capas: {len(model.layers)}")
        
        return model
        
    except Exception as e:
        print(f"‚ùå Error cargando modelo: {e}")
        return None

def test_labels_loading():
    """Probar carga de etiquetas"""
    print("\nüìã PRUEBA DE CARGA DE ETIQUETAS")
    print("=" * 50)
    
    try:
        labels_path = Path("models/class_labels.json")
        
        with open(labels_path, 'r', encoding='utf-8') as f:
            labels = json.load(f)
        
        print(f"‚úÖ Etiquetas cargadas exitosamente")
        print(f"üìä Total de razas: {len(labels)}")
        
        print(f"\nüêÑ Razas disponibles:")
        for breed, idx in labels.items():
            print(f"   {idx}: {breed}")
        
        return labels
        
    except Exception as e:
        print(f"‚ùå Error cargando etiquetas: {e}")
        return None

def test_prediction(model, labels):
    """Probar predicci√≥n del modelo"""
    print("\nüß™ PRUEBA DE PREDICCI√ìN")
    print("=" * 50)
    
    try:
        # Crear imagen dummy
        dummy_image = tf.random.normal((1, 224, 224, 3))
        
        # Medir tiempo de predicci√≥n
        start_time = time.time()
        predictions = model.predict(dummy_image, verbose="silent")
        prediction_time = time.time() - start_time
        
        # Obtener resultado
        predicted_class = np.argmax(predictions[0])
        confidence = float(predictions[0][predicted_class])
        
        # Encontrar raza predicha
        predicted_breed = None
        for breed, idx in labels.items():
            if idx == predicted_class:
                predicted_breed = breed
                break
        
        print(f"‚úÖ Predicci√≥n exitosa")
        print(f"‚è±Ô∏è Tiempo de predicci√≥n: {prediction_time:.3f} segundos")
        print(f"üéØ Raza predicha: {predicted_breed}")
        print(f"üìä Confianza: {confidence:.2%}")
        
        # Mostrar todas las predicciones
        print(f"\nüìà Predicciones por raza:")
        for breed, idx in labels.items():
            prob = float(predictions[0][idx])
            print(f"   {breed}: {prob:.2%}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error en predicci√≥n: {e}")
        return False

def test_server_integration():
    """Probar integraci√≥n con el servidor"""
    print("\nüåê PRUEBA DE INTEGRACI√ìN CON SERVIDOR")
    print("=" * 50)
    
    try:
        # Importar componentes del servidor
        from config.settings import Settings
        from data.datasources import TensorFlowDataSourceImpl
        
        # Cargar configuraci√≥n
        settings = Settings()
        print(f"‚úÖ Configuraci√≥n cargada")
        print(f"   Modelo: {settings.MODEL_PATH}")
        print(f"   Etiquetas: {settings.LABELS_PATH}")
        print(f"   Tama√±o imagen: {settings.IMAGE_SIZE}x{settings.IMAGE_SIZE}")
        print(f"   Razas configuradas: {len(settings.BOVINE_BREEDS)}")
        
        # Probar datasource
        datasource = TensorFlowDataSourceImpl()
        print(f"‚úÖ Datasource creado")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error en integraci√≥n: {e}")
        return False

def run_complete_verification():
    """Ejecutar verificaci√≥n completa"""
    print("üîç VERIFICACI√ìN COMPLETA DEL MODELO BOVINO")
    print("=" * 60)
    
    results = {}
    
    # 1. Verificar archivos
    results['files'] = verify_model_files()
    if not results['files']:
        return False
    
    # 2. Probar carga del modelo
    model = test_model_loading()
    results['model_loading'] = model is not None
    
    # 3. Probar carga de etiquetas
    labels = test_labels_loading()
    results['labels_loading'] = labels is not None
    
    # 4. Probar predicci√≥n
    if model and labels:
        results['prediction'] = test_prediction(model, labels)
    else:
        results['prediction'] = False
    
    # 5. Probar integraci√≥n con servidor
    results['server_integration'] = test_server_integration()
    
    # Resumen final
    print("\n" + "=" * 60)
    print("üìä RESUMEN DE VERIFICACI√ìN")
    print("=" * 60)
    
    all_passed = True
    for test_name, passed in results.items():
        status = "‚úÖ" if passed else "‚ùå"
        print(f"{status} {test_name.replace('_', ' ').title()}")
        if not passed:
            all_passed = False
    
    if all_passed:
        print(f"\nüéâ ¬°VERIFICACI√ìN COMPLETADA EXITOSAMENTE!")
        print(f"üöÄ Tu modelo est√° listo para usar en la aplicaci√≥n Flutter")
        print(f"üí° Puedes ejecutar: python main.py para iniciar el servidor")
    else:
        print(f"\n‚ùå Algunas verificaciones fallaron")
        print(f"üîß Revisa los errores anteriores para solucionarlos")
    
    return all_passed

if __name__ == "__main__":
    success = run_complete_verification()
    exit(0 if success else 1) 